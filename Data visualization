import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import PowerTransformer
#1.Make a heatmap of the value of the Goldstein–Price function
def plot_goldstein_price():
    # Define Goldstein–Price function
    def goldstein_price(x1, x2):
        term1 = (1 + ((x1 + x2 + 1)**2) * (19 - 14*x1 + 3*x1**2 - 14*x2 + 6*x1*x2 + 3*x2**2))
        term2 = (30 + ((2*x1 - 3*x2)**2) * (18 - 32*x1 + 12*x1**2 + 48*x2 - 36*x1*x2 + 27*x2**2))
        return term1 * term2
    # Compute the values for the grid
    x1 = np.linspace(-2, 2, 1000)
    x2 = np.linspace(-2, 2, 1000)
    X1, X2 = np.meshgrid(x1, x2)
    Z = goldstein_price(X1, X2)
    # Plot the heatmap
    plt.figure(figsize=(8, 6))
    ax = sns.heatmap(Z, cbar_kws={'label': 'Value'})
    tick_positions = np.linspace(0, len(x1) - 1, 5)
    tick_labels = [-2, -1, 0, 1, 2]
    ax.set_xticks(tick_positions)
    ax.set_xticklabels(tick_labels)
    ax.set_yticks(tick_positions)
    ax.set_yticklabels(tick_labels)
    plt.title("Heatmap of the Goldstein–Price Function")
    plt.xlabel('X1')
    plt.ylabel('X2')
    plt.show()
#2.The Goldstein–Price function is not stationary.
# Its values vary dramatically throughout its domain, characterized by regions of sharp peaks.
# Regions with high function values are near (x1,x2)=(-2,2) or (2,-2), where the function will have a very high value.
#That is, the behavior of the function appears not to be constant throughout the domain
#3.Can you find a transformation of the data that makes it more stationary?
#Picheny et al. (2012) use the following logarithmic form of the Goldstein-Price function, on [0, 1]**2
# Define the transformed Goldstein–Price function
def plot_transformed_goldstein_price():
    # Define the transformed Goldstein–Price function
    def transformed_goldstein_price(x1, x2):
        x1_bar = 4 * x1 - 2
        x2_bar = 4 * x2 - 2
        term1 = (1 + (x1_bar + x2_bar + 1) ** 2 * (
                    19 - 14 * x1_bar + 3 * x1_bar ** 2 - 14 * x2_bar + 6 * x1_bar * x2_bar + 3 * x2_bar ** 2))
        term2 = (30 + (2 * x1_bar - 3 * x2_bar) ** 2 * (
                    18 - 32 * x1_bar + 12 * x1_bar ** 2 + 48 * x2_bar - 36 * x1_bar * x2_bar + 27 * x2_bar ** 2))
        return (1 / 2.427) * np.log(term1 * term2) - 8.693
    x1 = np.linspace(-2, 2, 1000)
    x2 = np.linspace(-2, 2, 1000)
    X1, X2 = np.meshgrid(x1, x2)
    Z_transformed = transformed_goldstein_price(X1, X2)
    # Plot the heatmap for the transformed function
    plt.figure(figsize=(8, 6))
    ax = sns.heatmap(Z_transformed, cbar_kws={'label': 'Transformed Value'})
    tick_positions = np.linspace(0, len(x1) - 1, 5)
    tick_labels = [-2,-1,0,1,2]
    ax.set_xticks(tick_positions)
    ax.set_xticklabels(tick_labels)
    ax.set_yticks(tick_positions)
    ax.set_yticklabels(tick_labels)
    plt.title("Heatmap of the Transformed Goldstein–Price Function")
    plt.xlabel('X1')
    plt.ylabel('X2')
    plt.show()
#4.Make a kernel density estimate of the distribution of the values for the lda and svm benchmarks
def KDE_lda_and_svm(lda_file_path, svm_file_path):
    # Load data
    lda_data = pd.read_csv(lda_file_path)
    svm_data = pd.read_csv(svm_file_path)
    lda_target_values = pd.to_numeric(lda_data.iloc[:, 3], errors='coerce').dropna().values
    svm_target_values = pd.to_numeric(svm_data.iloc[:, 3], errors='coerce').dropna().values
    sns.set()
    # Plot KDE for LDA
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.kdeplot(data=lda_target_values, bw_method='scott', ax=ax, color="blue", label="LDA KDE")
    ax.plot(lda_target_values, np.zeros_like(lda_target_values), 'o', markersize=5, color='blue', alpha=0.7, label="LDA Points")
    ax.set_title("LDA Kernel Density Estimate")
    ax.set_xlabel("Benchmark Value")
    ax.set_ylabel("Density")
    ax.legend()
    plt.show()
    # Plot KDE for SVM
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.kdeplot(data=svm_target_values, bw_method='scott', ax=ax, color="green", label="SVM KDE")
    ax.plot(svm_target_values, np.zeros_like(svm_target_values), 'o', markersize=5, color='green', alpha=0.7, label="SVM Points")
    ax.set_title("SVM Kernel Density Estimate")
    ax.set_xlabel("Benchmark Value")
    ax.set_ylabel("Density")
    ax.legend()
    plt.show()

def transformed_KDE(lda_file_path, svm_file_path):
    lda_data = pd.read_csv(lda_file_path)
    svm_data = pd.read_csv(svm_file_path)
    lda_target_values = pd.to_numeric(lda_data.iloc[:, 3], errors='coerce').dropna().values
    svm_target_values = pd.to_numeric(svm_data.iloc[:, 3], errors='coerce').dropna().values
    power_transformer = PowerTransformer(method='box-cox', standardize=True)
    lda_transformed = power_transformer.fit_transform(lda_target_values.reshape(-1, 1)).flatten()
    svm_transformed = power_transformer.fit_transform(svm_target_values.reshape(-1, 1)).flatten()
    sns.set()
    # Plot KDE for LDA
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.kdeplot(data=lda_transformed, bw_method='scott', ax=ax, color="blue", label="LDA KDE")
    ax.plot(lda_transformed, np.zeros_like(lda_transformed), 'o', markersize=5, color='blue', alpha=0.7,
            label="LDA Points")
    ax.set_title("LDA Kernel Density Estimate")
    ax.set_xlabel("Benchmark Value")
    ax.set_ylabel("Density")
    ax.legend()
    plt.show()
    # Plot KDE for SVM
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.kdeplot(data=svm_transformed, bw_method='scott', ax=ax, color="green", label="SVM KDE")
    ax.plot(svm_transformed, np.zeros_like(svm_transformed), 'o', markersize=5, color='green', alpha=0.7,
            label="SVM Points")
    ax.set_title("SVM Kernel Density Estimate")
    ax.set_xlabel("Benchmark Value")
    ax.set_ylabel("Density")
    ax.legend()
    plt.show()
if __name__ == "__main__":
    plot_goldstein_price()
    plot_transformed_goldstein_price()
    KDE_lda_and_svm(r"C:\Users\Lenovo\Desktop\lda.csv",r"C:\Users\Lenovo\Desktop\svm.csv")
    transformed_KDE(r"C:\Users\Lenovo\Desktop\lda.csv",r"C:\Users\Lenovo\Desktop\svm.csv")
